{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "### Name:\n",
    "### Roll Number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross-validation is a technique used to assess and optimize the performance of machine\n",
    "# learning models. The dataset is divided into K subsets, or ”folds.” The model is trained on K-1 folds\n",
    "# and tested on the remaining one. This process is repeated K times, and the average performance\n",
    "# is used to gauge the model’s generalization ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001013</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2333</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP002731</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>18165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001449</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3865</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001238</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP002422</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>37719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001013    Male     Yes          0  Not Graduate            No   \n",
       "1  LP002731  Female      No          0  Not Graduate           Yes   \n",
       "2  LP001449    Male      No          0      Graduate            No   \n",
       "3  LP001238    Male     Yes         3+  Not Graduate           Yes   \n",
       "4  LP002422    Male      No          1      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             2333             1516.0        95.0             360.0   \n",
       "1            18165                0.0       125.0             360.0   \n",
       "2             3865             1640.0         NaN             360.0   \n",
       "3             7100                0.0       125.0              60.0   \n",
       "4            37719                0.0       152.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Urban           Y  \n",
       "2             1.0         Rural           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0     Semiurban           Y  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('../../dataset/cross-validation.csv')\n",
    "# randomize the dataset\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 12) (96, 12)\n",
      "Accuracy Score:  0.8125\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.85      0.41      0.55        27\n",
      "           Y       0.81      0.97      0.88        69\n",
      "\n",
      "    accuracy                           0.81        96\n",
      "   macro avg       0.83      0.69      0.72        96\n",
      "weighted avg       0.82      0.81      0.79        96\n",
      "\n",
      "Confusion Matrix: \n",
      " [[11 16]\n",
      " [ 2 67]]\n",
      "Accuracy Score:  0.7604166666666666\n",
      "Accuracy Score:  0.8125\n",
      "Accuracy Score:  0.7708333333333334\n",
      "Accuracy Score:  0.8645833333333334\n",
      "Accuracy Score:  0.8125\n",
      "Average Accuracy Score:  0.8041666666666668\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# drop the Loan_ID column\n",
    "dataset = dataset.drop(columns=['Loan_ID'], axis=1)\n",
    "\n",
    "# shape of the dataset\n",
    "dataset.shape\n",
    "\n",
    "# remove the rows with missing values\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# split the dataset into train and test\n",
    "train = dataset[:int(0.8*len(dataset))]\n",
    "test = dataset[int(0.8*len(dataset)):]\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "# split the train and test into X and Y\n",
    "X_train = train.drop(columns=['Loan_Status'])\n",
    "y_train = train['Loan_Status']\n",
    "X_test = test.drop(columns=['Loan_Status'])\n",
    "y_test = test['Loan_Status']\n",
    "\n",
    "# encode the categorical features\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "def encode(data):\n",
    "    for i in data.columns:\n",
    "        if data[i].dtype == 'object':\n",
    "            le.fit(data[i].astype(str))\n",
    "            data[i] = le.transform(data[i].astype(str))\n",
    "    return data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = encode(X_train)\n",
    "X_test = encode(X_test)\n",
    "\n",
    "# scale the data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# create the model with saga solver\n",
    "model = LogisticRegression(solver='saga', max_iter=20000)\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print the classification report\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# make the 5-fold cross validation\n",
    "\n",
    "k = 5\n",
    "size = len(dataset) // k\n",
    "acc = []\n",
    "for i in range(k):\n",
    "    # create 5 folds of the train data and make validation set\n",
    "    val = dataset[i*size: (i+1)*size]\n",
    "    train = dataset.drop(val.index)\n",
    "    # split the train and test into X and Y\n",
    "    X_train = train.drop(columns=['Loan_Status'])\n",
    "    y_train = train['Loan_Status']\n",
    "    X_test = val.drop(columns=['Loan_Status'])\n",
    "    y_test = val['Loan_Status']\n",
    "    \n",
    "    X_train = encode(X_train)\n",
    "    X_test = encode(X_test)\n",
    "    \n",
    "    # scale the data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # create the model with saga solver\n",
    "    model = LogisticRegression(solver='saga', max_iter=2000)\n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # print the accuracy score\n",
    "    print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print(\"Average Accuracy Score: \", np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
